{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windilt/Adafruit_ILI9341_8bit_STM/blob/master/%E2%80%9CYourMT3%2B_Demo_2024%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHT1qsB9EoXo"
      },
      "source": [
        "# 🎶 **YourMT3+**  \n",
        "\"YourMT3+: Multi-instrument Music Transcription with Enhanced Transformer Architectures and Cross-dataset Stem Augmentation\"\n",
        "\n",
        "<div>\n",
        "<img src=\"https://i.imgur.com/yfa53Xn.jpeg\" width=\"800\" />\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 🥁 How to use:\n",
        "1. Execute the code blocks below in sequence.\n",
        "2. In the GradIO interface, select either 'Audio upload' or 'YouTube' via the tabs.\n",
        "3. Click on \"Play\" or \"Transcribe\".\n",
        "\n",
        "#### Known Issues:\n",
        "- After changing the model checkpoint, a restart is required.\n",
        "- When transcribing music from sources outside the dataset, models trained with Pitch-shift (PS) often incorrectly transcribe segments a semitone higher or lower. This issue is not observed in the YPTF-S (noPS) model, as seen in the example at https://youtu.be/9E82wwNc7r8?si=I-WyfwJXCBDY2reh."
      ],
      "metadata": {
        "id": "rxrEok0DvPtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3f8ajcZesi-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7657f61-cbc5-4dfa-fa9f-874be281fecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.33.26-py3-none-any.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore==1.34.144 (from awscli)\n",
            "  Downloading botocore-1.34.144-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docutils<0.17,>=0.10 (from awscli)\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.11.0,>=0.10.0 (from awscli)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (6.0.1)\n",
            "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.34.144->awscli)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.144->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.34.144->awscli) (2.0.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.144->awscli) (1.16.0)\n",
            "Installing collected packages: rsa, jmespath, docutils, colorama, botocore, s3transfer, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "Successfully installed awscli-1.33.26 botocore-1.34.144 colorama-0.4.6 docutils-0.16 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.10.2\n",
            "download: s3://amt-deploy-public/amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/result_mc13_full_plus_256_default_rwc_pop_bass.json to amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/result_mc13_full_plus_256_default_rwc_pop_bass.json\n",
            "download: s3://amt-deploy-public/amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/.DS_Store to amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/.DS_Store\n",
            "download: s3://amt-deploy-public/amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/checkpoints/.DS_Store to amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/checkpoints/.DS_Store\n",
            "download: s3://amt-deploy-public/amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/result_mc13_full_plus_256_default_all_eval_final.json to amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/result_mc13_full_plus_256_default_all_eval_final.json\n",
            "download: s3://amt-deploy-public/amt/logs/2024/notask_all_cross_v6_xk2_amp0811_gm_ext_plus_nops_b72/result_mt3_full_plus_default_all_eval_final.json to amt/logs/2024/notask_all_cross_v6_xk2_amp0811_gm_ext_plus_nops_b72/result_mt3_full_plus_default_all_eval_final.json\n",
            "download: s3://amt-deploy-public/amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/result_mc13_full_plus_256_default_mir_st500_voc_debug.json to amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/result_mc13_full_plus_256_default_mir_st500_voc_debug.json\n",
            "download: s3://amt-deploy-public/amt/src/.coveragerc to amt/src/.coveragerc\n",
            "download: s3://amt-deploy-public/amt/src/.coverage to amt/src/.coverage\n",
            "download: s3://amt-deploy-public/amt/src/.pytest_cache/.gitignore to amt/src/.pytest_cache/.gitignore\n",
            "download: s3://amt-deploy-public/amt/src/.pytest_cache/README.md to amt/src/.pytest_cache/README.md\n",
            "download: s3://amt-deploy-public/amt/src/.pytest_cache/CACHEDIR.TAG to amt/src/.pytest_cache/CACHEDIR.TAG\n",
            "download: s3://amt-deploy-public/amt/src/.pytest_cache/v/cache/lastfailed to amt/src/.pytest_cache/v/cache/lastfailed\n",
            "download: s3://amt-deploy-public/amt/src/.pytest_cache/v/cache/nodeids to amt/src/.pytest_cache/v/cache/nodeids\n",
            "download: s3://amt-deploy-public/amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/checkpoints/last.ckpt to amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/checkpoints/last.ckpt\n",
            "download: s3://amt-deploy-public/amt/src/.pytest_cache/v/cache/stepwise to amt/src/.pytest_cache/v/cache/stepwise\n",
            "download: s3://amt-deploy-public/amt/logs/2024/ptf_all_cross_rebal5_mirst_xk2_edr005_attend_c_full_plus_b100/checkpoints/model.ckpt to amt/logs/2024/ptf_all_cross_rebal5_mirst_xk2_edr005_attend_c_full_plus_b100/checkpoints/model.ckpt\n",
            "download: s3://amt-deploy-public/amt/logs/2024/notask_all_cross_v6_xk2_amp0811_gm_ext_plus_nops_b72/checkpoints/model.ckpt to amt/logs/2024/notask_all_cross_v6_xk2_amp0811_gm_ext_plus_nops_b72/checkpoints/model.ckpt\n",
            "download: s3://amt-deploy-public/amt/src/config/config.py to amt/src/config/config.py\n",
            "download: s3://amt-deploy-public/amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b80_ps2/checkpoints/model.ckpt to amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b80_ps2/checkpoints/model.ckpt\n",
            "download: s3://amt-deploy-public/amt/src/config/vocabulary.py to amt/src/config/vocabulary.py\n",
            "download: s3://amt-deploy-public/amt/src/config/.DS_Store to amt/src/config/.DS_Store\n",
            "download: s3://amt-deploy-public/amt/src/extras/.DS_Store to amt/src/extras/.DS_Store\n",
            "download: s3://amt-deploy-public/amt/src/extras/check_drum_channel_slakh.py to amt/src/extras/check_drum_channel_slakh.py\n",
            "download: s3://amt-deploy-public/amt/src/config/data_presets.py to amt/src/config/data_presets.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/dataset_mutable_var_sanity_check.py to amt/src/extras/dataset_mutable_var_sanity_check.py\n",
            "download: s3://amt-deploy-public/amt/src/config/task.py to amt/src/config/task.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/Dockerfile to amt/src/extras/Dockerfile\n",
            "download: s3://amt-deploy-public/amt/src/extras/datasets_eval_testing.py to amt/src/extras/datasets_eval_testing.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/.DS_Store to amt/src/extras/examples/.DS_Store\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/1727.mid to amt/src/extras/examples/1727.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/1733.mid to amt/src/extras/examples/1733.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/2106.mid to amt/src/extras/examples/2106.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/803_002_167s95.mid to amt/src/extras/examples/803_002_167s95.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/805_S00_8s83.mid to amt/src/extras/examples/805_S00_8s83.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/piano.mid to amt/src/extras/examples/piano.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/drum.mid to amt/src/extras/examples/drum.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/drum_converted.mid to amt/src/extras/examples/drum_converted.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/piano_converted.mid to amt/src/extras/examples/piano_converted.mid\n",
            "download: s3://amt-deploy-public/amt/src/extras/download_mirst500.py to amt/src/extras/download_mirst500.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/singing_notes.npy to amt/src/extras/examples/singing_notes.npy\n",
            "download: s3://amt-deploy-public/amt/src/extras/demo_intra_augmentation.py to amt/src/extras/demo_intra_augmentation.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/fig/pitchshift_stretch_and_resampler_process_time.png to amt/src/extras/fig/pitchshift_stretch_and_resampler_process_time.png\n",
            "download: s3://amt-deploy-public/amt/src/extras/demo_cross_augmentation.py to amt/src/extras/demo_cross_augmentation.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/fig/label_smooth_interval_of_interest.png to amt/src/extras/fig/label_smooth_interval_of_interest.png\n",
            "download: s3://amt-deploy-public/amt/src/extras/inspecting_slakh_bass.py to amt/src/extras/inspecting_slakh_bass.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/install_deepspeed.md to amt/src/extras/install_deepspeed.md\n",
            "download: s3://amt-deploy-public/amt/src/extras/label_smoothing.py to amt/src/extras/label_smoothing.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/multi_channel_seqlen_stats.py to amt/src/extras/multi_channel_seqlen_stats.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/perceivertf_inspect.py to amt/src/extras/perceivertf_inspect.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/npy_speed_benchmark.py to amt/src/extras/npy_speed_benchmark.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/perceivertf_multi_inspect.py to amt/src/extras/perceivertf_multi_inspect.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/pitch_shift_benchmark.py to amt/src/extras/pitch_shift_benchmark.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/run_spleeter_mir1k.sh to amt/src/extras/run_spleeter_mir1k.sh\n",
            "download: s3://amt-deploy-public/amt/src/extras/examples/singing_note_events.npy to amt/src/extras/examples/singing_note_events.npy\n",
            "download: s3://amt-deploy-public/amt/src/extras/run_spleeter_mirst500_cmedia.sh to amt/src/extras/run_spleeter_mirst500_cmedia.sh\n",
            "download: s3://amt-deploy-public/amt/src/extras/swap_channel.py to amt/src/extras/swap_channel.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/run_spleeter_mirst500.sh to amt/src/extras/run_spleeter_mirst500.sh\n",
            "download: s3://amt-deploy-public/amt/src/extras/t5_dev.py to amt/src/extras/t5_dev.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/t5perceiver.py to amt/src/extras/t5perceiver.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/unimax_sampler/README.md to amt/src/extras/unimax_sampler/README.md\n",
            "download: s3://amt-deploy-public/amt/src/extras/unimax_sampler/demo.py to amt/src/extras/unimax_sampler/demo.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/unimax_sampler/unimax_sampler.py to amt/src/extras/unimax_sampler/unimax_sampler.py\n",
            "download: s3://amt-deploy-public/amt/logs/2024/ptf_mc13_256_all_cross_v6_xk5_amp0811_edr005_attend_c_full_plus_2psn_nl26_sb_b26r_800k/checkpoints/model.ckpt to amt/logs/2024/ptf_mc13_256_all_cross_v6_xk5_amp0811_edr005_attend_c_full_plus_2psn_nl26_sb_b26r_800k/checkpoints/model.ckpt\n",
            "download: s3://amt-deploy-public/amt/src/install_dataset.py to amt/src/install_dataset.py\n",
            "download: s3://amt-deploy-public/amt/src/model/conformer_helper.py to amt/src/model/conformer_helper.py\n",
            "download: s3://amt-deploy-public/amt/src/model/ff_layer.py to amt/src/model/ff_layer.py\n",
            "download: s3://amt-deploy-public/amt/src/model/init_train.py to amt/src/model/init_train.py\n",
            "download: s3://amt-deploy-public/amt/src/model/conformer_mod.py to amt/src/model/conformer_mod.py\n",
            "download: s3://amt-deploy-public/amt/src/model/conv_block.py to amt/src/model/conv_block.py\n",
            "download: s3://amt-deploy-public/amt/src/model/lr_scheduler.py to amt/src/model/lr_scheduler.py\n",
            "download: s3://amt-deploy-public/amt/src/model/lm_head.py to amt/src/model/lm_head.py\n",
            "download: s3://amt-deploy-public/amt/src/model/ops.py to amt/src/model/ops.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/fig/pitchshift_benchnmark.png to amt/src/extras/fig/pitchshift_benchnmark.png\n",
            "download: s3://amt-deploy-public/amt/src/extras/rotary_positional_embedding.py to amt/src/extras/rotary_positional_embedding.py\n",
            "download: s3://amt-deploy-public/amt/src/extras/remove_silence_musicnet_midi.py to amt/src/extras/remove_silence_musicnet_midi.py\n",
            "download: s3://amt-deploy-public/amt/src/model/perceiver_helper.py to amt/src/model/perceiver_helper.py\n",
            "download: s3://amt-deploy-public/amt/src/model/RoPE/RoPE.py to amt/src/model/RoPE/RoPE.py\n",
            "download: s3://amt-deploy-public/amt/src/model/optimizers.py to amt/src/model/optimizers.py\n",
            "download: s3://amt-deploy-public/amt/src/model/pitchshift_layer.py to amt/src/model/pitchshift_layer.py\n",
            "download: s3://amt-deploy-public/amt/src/model/positional_encoding.py to amt/src/model/positional_encoding.py\n",
            "download: s3://amt-deploy-public/amt/src/model/projection_layer.py to amt/src/model/projection_layer.py\n",
            "download: s3://amt-deploy-public/amt/src/model/perceiver_mod.py to amt/src/model/perceiver_mod.py\n",
            "download: s3://amt-deploy-public/amt/src/model/t5mod.py to amt/src/model/t5mod.py\n",
            "download: s3://amt-deploy-public/amt/src/pytest.ini to amt/src/pytest.ini\n",
            "download: s3://amt-deploy-public/amt/src/model/ymt3.py to amt/src/model/ymt3.py\n",
            "download: s3://amt-deploy-public/amt/src/model/t5mod_helper.py to amt/src/model/t5mod_helper.py\n",
            "download: s3://amt-deploy-public/amt/src/requirements.txt to amt/src/requirements.txt\n",
            "download: s3://amt-deploy-public/amt/src/model/spectrogram.py to amt/src/model/spectrogram.py\n",
            "download: s3://amt-deploy-public/amt/src/test.py to amt/src/test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/audio_test.py to amt/src/tests/audio_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/.DS_Store to amt/src/tests/.DS_Store\n",
            "download: s3://amt-deploy-public/amt/src/tests/assert_fns.py to amt/src/tests/assert_fns.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/metrics_test.py to amt/src/tests/metrics_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/event2note_test.py to amt/src/tests/event2note_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/event_codec_test.py to amt/src/tests/event_codec_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/midi_test.py to amt/src/tests/midi_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/note2event_test.py to amt/src/tests/note2event_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/model/spectrogram_test.py to amt/src/tests/model/spectrogram_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/model/ops_test.py to amt/src/tests/model/ops_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/note_event_roundtrip_test.py to amt/src/tests/note_event_roundtrip_test.py\n",
            "download: s3://amt-deploy-public/amt/src/tests/tokenizer_test.py to amt/src/tests/tokenizer_test.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/README.md to amt/src/utils/README.md\n",
            "download: s3://amt-deploy-public/amt/src/tests/utils_test.py to amt/src/tests/utils_test.py\n",
            "download: s3://amt-deploy-public/amt/src/train.py to amt/src/train.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/audio.py to amt/src/utils/audio.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/datasets_eval.py to amt/src/utils/datasets_eval.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/data_modules.py to amt/src/utils/data_modules.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/datasets_train.py to amt/src/utils/datasets_train.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/datasets_helper.py to amt/src/utils/datasets_helper.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/augment.py to amt/src/utils/augment.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/event2note.py to amt/src/utils/event2note.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/event_codec.py to amt/src/utils/event_codec.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/metrics_helper.py to amt/src/utils/metrics_helper.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/metrics.py to amt/src/utils/metrics.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/mirdata_dev/.DS_Store to amt/src/utils/mirdata_dev/.DS_Store\n",
            "download: s3://amt-deploy-public/amt/src/utils/midi.py to amt/src/utils/midi.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/note2event.py to amt/src/utils/note2event.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/mirdata_dev/datasets/slakh16k.py to amt/src/utils/mirdata_dev/datasets/slakh16k.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/mirdata_dev/scripts/make_slakh_index.py to amt/src/utils/mirdata_dev/scripts/make_slakh_index.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/note_event_dataclasses.py to amt/src/utils/note_event_dataclasses.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/dataset_stats.py to amt/src/utils/preprocess/dataset_stats.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/generate_dataset_stats.py to amt/src/utils/preprocess/generate_dataset_stats.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_cmedia.py to amt/src/utils/preprocess/preprocess_cmedia.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_egmd.py to amt/src/utils/preprocess/preprocess_egmd.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_enstdrums.py to amt/src/utils/preprocess/preprocess_enstdrums.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_geerdes.py to amt/src/utils/preprocess/preprocess_geerdes.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_guitarset.py to amt/src/utils/preprocess/preprocess_guitarset.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_idmt_smt_bass.py to amt/src/utils/preprocess/preprocess_idmt_smt_bass.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_maestro.py to amt/src/utils/preprocess/preprocess_maestro.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_maps.py to amt/src/utils/preprocess/preprocess_maps.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_mir1k.py to amt/src/utils/preprocess/preprocess_mir1k.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_mir_st500.py to amt/src/utils/preprocess/preprocess_mir_st500.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_rnsynth.py to amt/src/utils/preprocess/preprocess_rnsynth.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_musicnet.py to amt/src/utils/preprocess/preprocess_musicnet.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/task_manager.py to amt/src/utils/task_manager.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_rwc_pop.py to amt/src/utils/preprocess/preprocess_rwc_pop.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_slakh.py to amt/src/utils/preprocess/preprocess_slakh.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/tokenizer.py to amt/src/utils/tokenizer.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/utils.py to amt/src/utils/utils.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_rwc_pop_full.py to amt/src/utils/preprocess/preprocess_rwc_pop_full.py\n",
            "download: s3://amt-deploy-public/amt/src/utils/preprocess/preprocess_urmp.py to amt/src/utils/preprocess/preprocess_urmp.py\n",
            "download: s3://amt-deploy-public/examples/MAPS_MUS-chpn-e01_ENSTDkCl.wav to examples/MAPS_MUS-chpn-e01_ENSTDkCl.wav\n",
            "download: s3://amt-deploy-public/examples/MAPS_MUS-scn15_11_ENSTDkAm.wav to examples/MAPS_MUS-scn15_11_ENSTDkAm.wav\n",
            "download: s3://amt-deploy-public/examples/00_Funk1-97-C_comp_mic_pshift-3.wav to examples/00_Funk1-97-C_comp_mic_pshift-3.wav\n",
            "download: s3://amt-deploy-public/examples/musicnet_2628.wav to examples/musicnet_2628.wav\n",
            "download: s3://amt-deploy-public/examples/musicnet2556.wav to examples/musicnet2556.wav\n",
            "download: s3://amt-deploy-public/examples/Slakh_test_1884.wav to examples/Slakh_test_1884.wav\n",
            "download: s3://amt-deploy-public/examples/Slakh_test_1975.wav to examples/Slakh_test_1975.wav\n",
            "download: s3://amt-deploy-public/examples/rwc087.wav to examples/rwc087.wav\n",
            "download: s3://amt-deploy-public/examples/rwc089.mp3 to examples/rwc089.mp3\n",
            "download: s3://amt-deploy-public/examples/mirst493.wav to examples/mirst493.wav\n",
            "/content/amt/src\n",
            "Collecting git+https://github.com/craffel/mir_eval.git (from -r requirements.txt (line 3))\n",
            "  Cloning https://github.com/craffel/mir_eval.git to /tmp/pip-req-build-udarrfhj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/craffel/mir_eval.git /tmp/pip-req-build-udarrfhj\n",
            "  Resolved https://github.com/craffel/mir_eval.git to commit 485a42551f449517567313f9871f58e9c99fbd8a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup.git to /tmp/pip-req-build-fjouh4cb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup.git /tmp/pip-req-build-fjouh4cb\n",
            "  Resolved https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup.git to commit 12d03c07553aedd3d9e9155e2b3e31ce8c64081a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mirdata (from -r requirements.txt (line 1))\n",
            "  Downloading mirdata-0.3.8-py3-none-any.whl (17.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mido (from -r requirements.txt (line 2))\n",
            "  Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.7.1)\n",
            "Collecting lightning>=2.2.1 (from -r requirements.txt (line 6))\n",
            "  Downloading lightning-2.3.3-py3-none-any.whl (808 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest-timeout (from -r requirements.txt (line 7))\n",
            "  Downloading pytest_timeout-2.3.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (7.4.4)\n",
            "Collecting deprecated (from -r requirements.txt (line 9))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.10.2.post1)\n",
            "Collecting einops (from -r requirements.txt (line 11))\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (4.41.2)\n",
            "Collecting wandb (from -r requirements.txt (line 13))\n",
            "  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (7.0.4)\n",
            "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (23.2.0)\n",
            "Collecting black>=23.3.0 (from mirdata->-r requirements.txt (line 1))\n",
            "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (5.2.0)\n",
            "Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (3.9.0)\n",
            "Collecting jams>=0.3.4 (from mirdata->-r requirements.txt (line 1))\n",
            "  Downloading jams-0.3.4.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (2.0.3)\n",
            "Collecting pretty-midi>=0.2.10 (from mirdata->-r requirements.txt (line 1))\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from mirdata->-r requirements.txt (line 1)) (4.66.4)\n",
            "Collecting packaging~=23.1 (from mido->-r requirements.txt (line 2))\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: fsspec[http]<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.2.1->-r requirements.txt (line 6)) (2023.6.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Downloading lightning_utilities-0.11.5-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: torch<4.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.2.1->-r requirements.txt (line 6)) (2.3.0+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.2.1->-r requirements.txt (line 6)) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 8)) (2.0.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->-r requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (0.23.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (0.4.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 13)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 13))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 13))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 13)) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 13)) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 13)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 13))\n",
            "  Downloading sentry_sdk-2.10.0-py2.py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.1/302.1 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 13))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 13)) (67.7.2)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=23.3.0->mirdata->-r requirements.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=23.3.0->mirdata->-r requirements.txt (line 1))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 13)) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.2.1->-r requirements.txt (line 6)) (3.9.5)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 13))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jams>=0.3.4->mirdata->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: jsonschema>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from jams>=0.3.4->mirdata->-r requirements.txt (line 1)) (4.19.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 10)) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->mirdata->-r requirements.txt (line 1)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->mirdata->-r requirements.txt (line 1)) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->mirdata->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->mirdata->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->mirdata->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->mirdata->-r requirements.txt (line 1)) (2024.7.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 10)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6)) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6)) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.2.1->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.2.1->-r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.2.1->-r requirements.txt (line 6)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.2.1->-r requirements.txt (line 6)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.2.1->-r requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 10)) (2.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 13))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.0->jams>=0.3.4->mirdata->-r requirements.txt (line 1)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.0->jams>=0.3.4->mirdata->-r requirements.txt (line 1)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.0->jams>=0.3.4->mirdata->-r requirements.txt (line 1)) (0.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=2.0.0->lightning>=2.2.1->-r requirements.txt (line 6)) (1.3.0)\n",
            "Building wheels for collected packages: mir-eval, cosine-annealing-warmup, jams, pretty-midi\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.7-py3-none-any.whl size=102100 sha256=4fe6298944ba0f7a454423123b61aff9a4481861c76ba41e8b9de32e40d6006f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j98har6b/wheels/34/ea/c6/0ab59a0fe24019624b8271cfae39a7a751d8b1399e8ef6094c\n",
            "  Building wheel for cosine-annealing-warmup (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cosine-annealing-warmup: filename=cosine_annealing_warmup-2.0-py3-none-any.whl size=4165 sha256=8a28f9bc2b06a8449f61c61e23304c1e5eb0ee677ba6b94c2f3241fbc9a80ac9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j98har6b/wheels/65/1e/c4/77cef103bfe49587954d749d2278c70efb959f72a388343a0b\n",
            "  Building wheel for jams (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jams: filename=jams-0.3.4-py3-none-any.whl size=64900 sha256=307edd81579da6994a8482388c212d80b392722543dacb4b93a7a12b427c72f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/9a/f7/fb386b6bc5a75a3ef198a50e98b221e94a381472332b65cf24\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592289 sha256=14b99099d4796d554b1114bab10927cff357ad52dee3b0ef26ef55d78346fbf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built mir-eval cosine-annealing-warmup jams pretty-midi\n",
            "Installing collected packages: cosine-annealing-warmup, smmap, setproctitle, sentry-sdk, pathspec, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, einops, docker-pycreds, deprecated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mir-eval, mido, lightning-utilities, gitdb, black, pytest-timeout, pretty-midi, nvidia-cusolver-cu12, gitpython, wandb, jams, torchmetrics, mirdata, pytorch-lightning, lightning\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n"
          ]
        }
      ],
      "source": [
        "# @title Setup\n",
        "!pip install awscli\n",
        "!mkdir amt\n",
        "!aws s3 cp s3://amt-deploy-public/amt/ /content/amt --no-sign-request --recursive\n",
        "!aws s3 cp s3://amt-deploy-public/examples/ /content/examples --no-sign-request --recursive\n",
        "%cd amt/src\n",
        "!pip install -r requirements.txt\n",
        "!apt-get install sox\n",
        "!pip install gradio\n",
        "!pip install pytube\n",
        "!python -m pip install -U yt-dlp[default]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uUjYKGMnU_i3"
      },
      "outputs": [],
      "source": [
        "# @title Model helper\n",
        "%cd /content/amt/src\n",
        "from collections import Counter\n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from model.init_train import initialize_trainer, update_config\n",
        "from utils.task_manager import TaskManager\n",
        "from config.vocabulary import drum_vocab_presets\n",
        "from utils.utils import str2bool\n",
        "from utils.utils import Timer\n",
        "from utils.audio import slice_padded_array\n",
        "from utils.note2event import mix_notes\n",
        "from utils.event2note import merge_zipped_note_events_and_ties_to_notes\n",
        "from utils.utils import write_model_output_as_midi, write_err_cnt_as_json\n",
        "from model.ymt3 import YourMT3\n",
        "\n",
        "\n",
        "def load_model_checkpoint(args=None):\n",
        "    parser = argparse.ArgumentParser(description=\"YourMT3\")\n",
        "    # General\n",
        "    parser.add_argument('exp_id', type=str, help='A unique identifier for the experiment is used to resume training. The \"@\" symbol can be used to load a specific checkpoint.')\n",
        "    parser.add_argument('-p', '--project', type=str, default='ymt3', help='project name')\n",
        "    parser.add_argument('-ac', '--audio-codec', type=str, default=None, help='audio codec (default=None). {\"spec\", \"melspec\"}. If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-hop', '--hop-length', type=int, default=None, help='hop length in frames (default=None). {128, 300} 128 for MT3, 300 for PerceiverTFIf None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-nmel', '--n-mels', type=int, default=None, help='number of mel bins (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-if', '--input-frames', type=int, default=None, help='number of audio frames for input segment (default=None). If None, default value defined in config.py will be used.')\n",
        "    # Model configurations\n",
        "    parser.add_argument('-sqr', '--sca-use-query-residual', type=str2bool, default=None, help='sca use query residual flag. Default follows config.py')\n",
        "    parser.add_argument('-enc', '--encoder-type', type=str, default=None, help=\"Encoder type. 't5' or 'perceiver-tf' or 'conformer'. Default is 't5', following config.py.\")\n",
        "    parser.add_argument('-dec', '--decoder-type', type=str, default=None, help=\"Decoder type. 't5' or 'multi-t5'. Default is 't5', following config.py.\")\n",
        "    parser.add_argument('-preenc', '--pre-encoder-type', type=str, default='default', help=\"Pre-encoder type. None or 'conv' or 'default'. By default, t5_enc:None, perceiver_tf_enc:conv, conformer:None\")\n",
        "    parser.add_argument('-predec', '--pre-decoder-type', type=str, default='default', help=\"Pre-decoder type. {None, 'linear', 'conv1', 'mlp', 'group_linear'} or 'default'. Default is {'t5': None, 'perceiver-tf': 'linear', 'conformer': None}.\")\n",
        "    parser.add_argument('-cout', '--conv-out-channels', type=int, default=None, help='Number of filters for pre-encoder conv layer. Default follows \"model_cfg\" of config.py.')\n",
        "    parser.add_argument('-tenc', '--task-cond-encoder', type=str2bool, default=True, help='task conditional encoder (default=True). True or False')\n",
        "    parser.add_argument('-tdec', '--task-cond-decoder', type=str2bool, default=True, help='task conditional decoder (default=True). True or False')\n",
        "    parser.add_argument('-df', '--d-feat', type=int, default=None, help='Audio feature will be projected to this dimension for Q,K,V of T5 or K,V of Perceiver (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-pt', '--pretrained', type=str2bool, default=False, help='pretrained T5(default=False). True or False')\n",
        "    parser.add_argument('-b', '--base-name', type=str, default=\"google/t5-v1_1-small\", help='base model name (default=\"google/t5-v1_1-small\")')\n",
        "    parser.add_argument('-epe', '--encoder-position-encoding-type', type=str, default='default', help=\"Positional encoding type of encoder. By default, pre-defined PE for T5 or Perceiver-TF encoder in config.py. For T5: {'sinusoidal', 'trainable'}, conformer: {'rotary', 'trainable'}, Perceiver-TF: {'trainable', 'rope', 'alibi', 'alibit', 'None', '0', 'none', 'tkd', 'td', 'tk', 'kdt'}.\")\n",
        "    parser.add_argument('-dpe', '--decoder-position-encoding-type', type=str, default='default', help=\"Positional encoding type of decoder. By default, pre-defined PE for T5 in config.py. {'sinusoidal', 'trainable'}.\")\n",
        "    parser.add_argument('-twe', '--tie-word-embedding', type=str2bool, default=None, help='tie word embedding (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-el', '--event-length', type=int, default=None, help='event length (default=None). If None, default value defined in model cfg of config.py will be used.')\n",
        "    # Perceiver-TF configurations\n",
        "    parser.add_argument('-dl', '--d-latent', type=int, default=None, help='Latent dimension of Perceiver. On T5, this will be ignored (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-nl', '--num-latents', type=int, default=None, help='Number of latents of Perceiver. On T5, this will be ignored (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-dpm', '--perceiver-tf-d-model', type=int, default=None, help='Perceiver-TF d_model (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-npb', '--num-perceiver-tf-blocks', type=int, default=None, help='Number of blocks of Perceiver-TF. On T5, this will be ignored (default=None). If None, default value defined in config.py.')\n",
        "    parser.add_argument('-npl', '--num-perceiver-tf-local-transformers-per-block', type=int, default=None, help='Number of local layers per block of Perceiver-TF. On T5, this will be ignored (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-npt', '--num-perceiver-tf-temporal-transformers-per-block', type=int, default=None, help='Number of temporal layers per block of Perceiver-TF. On T5, this will be ignored (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-atc', '--attention-to-channel', type=str2bool, default=None, help='Attention to channel flag of Perceiver-TF. On T5, this will be ignored (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-ln', '--layer-norm-type', type=str, default=None, help='Layer normalization type (default=None). {\"layer_norm\", \"rms_norm\"}. If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-ff', '--ff-layer-type', type=str, default=None, help='Feed forward layer type (default=None). {\"mlp\", \"moe\", \"gmlp\"}. If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-wf', '--ff-widening-factor', type=int, default=None, help='Feed forward layer widening factor for MLP/MoE/gMLP (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-nmoe', '--moe-num-experts', type=int, default=None, help='Number of experts for MoE (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-kmoe', '--moe-topk', type=int, default=None, help='Top-k for MoE (default=None). If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-act', '--hidden-act', type=str, default=None, help='Hidden activation function (default=None). {\"gelu\", \"silu\", \"relu\", \"tanh\"}. If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-rt', '--rotary-type', type=str, default=None, help='Rotary embedding type expressed in three letters. e.g. ppl: \"pixel\" for SCA and latents, \"lang\" for temporal transformer. If None, use config.')\n",
        "    parser.add_argument('-rk', '--rope-apply-to-keys', type=str2bool, default=None, help='Apply rope to keys (default=None). If None, use config.')\n",
        "    parser.add_argument('-rp', '--rope-partial-pe', type=str2bool, default=None, help='Whether to apply RoPE to partial positions (default=None). If None, use config.')\n",
        "    # Decoder configurations\n",
        "    parser.add_argument('-dff', '--decoder-ff-layer-type', type=str, default=None, help='Feed forward layer type of decoder (default=None). {\"mlp\", \"moe\", \"gmlp\"}. If None, default value defined in config.py will be used.')\n",
        "    parser.add_argument('-dwf', '--decoder-ff-widening-factor', type=int, default=None, help='Feed forward layer widening factor for decoder MLP/MoE/gMLP (default=None). If None, default value defined in config.py will be used.')\n",
        "    # Task and Evaluation configurations\n",
        "    parser.add_argument('-tk', '--task', type=str, default='mt3_full_plus', help='tokenizer type (default=mt3_full_plus). See config/task.py for more options.')\n",
        "    parser.add_argument('-epv', '--eval-program-vocab', type=str, default=None, help='evaluation vocabulary (default=None). If None, default vocabulary of the data preset will be used.')\n",
        "    parser.add_argument('-edv', '--eval-drum-vocab', type=str, default=None, help='evaluation vocabulary for drum (default=None). If None, default vocabulary of the data preset will be used.')\n",
        "    parser.add_argument('-etk', '--eval-subtask-key', type=str, default='default', help='evaluation subtask key (default=default). See config/task.py for more options.')\n",
        "    parser.add_argument('-t', '--onset-tolerance', type=float, default=0.05, help='onset tolerance (default=0.05).')\n",
        "    parser.add_argument('-os', '--test-octave-shift', type=str2bool, default=False, help='test optimal octave shift (default=False). True or False')\n",
        "    parser.add_argument('-w', '--write-model-output', type=str2bool, default=True, help='write model test output to file (default=False). True or False')\n",
        "    # Trainer configurations\n",
        "    parser.add_argument('-pr','--precision', type=str, default=\"bf16-mixed\", help='precision (default=\"bf16-mixed\") {32, 16, bf16, bf16-mixed}')\n",
        "    parser.add_argument('-st', '--strategy', type=str, default='auto', help='strategy (default=auto). auto or deepspeed or ddp')\n",
        "    parser.add_argument('-n', '--num-nodes', type=int, default=1, help='number of nodes (default=1)')\n",
        "    parser.add_argument('-g', '--num-gpus', type=str, default='auto', help='number of gpus (default=\"auto\")')\n",
        "    parser.add_argument('-wb', '--wandb-mode', type=str, default=\"disabled\", help='wandb mode for logging (default=None). \"disabled\" or \"online\" or \"offline\". If None, default value defined in config.py will be used.')\n",
        "    # Debug\n",
        "    parser.add_argument('-debug', '--debug-mode', type=str2bool, default=False, help='debug mode (default=False). True or False')\n",
        "    parser.add_argument('-tps', '--test-pitch-shift', type=int, default=None, help='use pitch shift when testing. debug-purpose only. (default=None). semitone in int.')\n",
        "    args = parser.parse_args(args)\n",
        "    # yapf: enable\n",
        "    if torch.__version__ >= \"1.13\":\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "    args.epochs = None\n",
        "\n",
        "    # Initialize and update config\n",
        "    _, _, dir_info, shared_cfg = initialize_trainer(args, stage='test')\n",
        "    shared_cfg, audio_cfg, model_cfg = update_config(args, shared_cfg, stage='test')\n",
        "\n",
        "    if args.eval_drum_vocab != None:  # override eval_drum_vocab\n",
        "        eval_drum_vocab = drum_vocab_presets[args.eval_drum_vocab]\n",
        "\n",
        "    # Initialize task manager\n",
        "    tm = TaskManager(task_name=args.task,\n",
        "                     max_shift_steps=int(shared_cfg[\"TOKENIZER\"][\"max_shift_steps\"]),\n",
        "                     debug_mode=args.debug_mode)\n",
        "    print(f\"Task: {tm.task_name}, Max Shift Steps: {tm.max_shift_steps}\")\n",
        "\n",
        "    # Use GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Model\n",
        "    model = YourMT3(\n",
        "        audio_cfg=audio_cfg,\n",
        "        model_cfg=model_cfg,\n",
        "        shared_cfg=shared_cfg,\n",
        "        optimizer=None,\n",
        "        task_manager=tm,  # tokenizer is a member of task_manager\n",
        "        eval_subtask_key=args.eval_subtask_key,\n",
        "        write_output_dir=dir_info[\"lightning_dir\"] if args.write_model_output or args.test_octave_shift else None\n",
        "        ).to(device)\n",
        "    checkpoint = torch.load(dir_info[\"last_ckpt_path\"])\n",
        "    state_dict = checkpoint['state_dict']\n",
        "    new_state_dict = {k: v for k, v in state_dict.items() if 'pitchshift' not in k}\n",
        "    model.load_state_dict(new_state_dict, strict=False)\n",
        "    return model.eval()\n",
        "\n",
        "\n",
        "def transcribe(model, audio_info):\n",
        "    t = Timer()\n",
        "\n",
        "    # Converting Audio\n",
        "    t.start()\n",
        "    audio, sr = torchaudio.load(uri=audio_info['filepath'])\n",
        "    audio = torch.mean(audio, dim=0).unsqueeze(0)\n",
        "    audio = torchaudio.functional.resample(audio, sr, model.audio_cfg['sample_rate'])\n",
        "    audio_segments = slice_padded_array(audio, model.audio_cfg['input_frames'], model.audio_cfg['input_frames'])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    audio_segments = torch.from_numpy(audio_segments.astype('float32')).to(device).unsqueeze(1) # (n_seg, 1, seg_sz)\n",
        "    t.stop(); t.print_elapsed_time(\"converting audio\");\n",
        "\n",
        "    # Inference\n",
        "    t.start()\n",
        "    pred_token_arr, _ = model.inference_file(bsz=8, audio_segments=audio_segments)\n",
        "    t.stop(); t.print_elapsed_time(\"model inference\");\n",
        "\n",
        "    # Post-processing\n",
        "    t.start()\n",
        "    num_channels = model.task_manager.num_decoding_channels\n",
        "    n_items = audio_segments.shape[0]\n",
        "    start_secs_file = [model.audio_cfg['input_frames'] * i / model.audio_cfg['sample_rate'] for i in range(n_items)]\n",
        "    pred_notes_in_file = []\n",
        "    n_err_cnt = Counter()\n",
        "    for ch in range(num_channels):\n",
        "        pred_token_arr_ch = [arr[:, ch, :] for arr in pred_token_arr]  # (B, L)\n",
        "        zipped_note_events_and_tie, list_events, ne_err_cnt = model.task_manager.detokenize_list_batches(\n",
        "            pred_token_arr_ch, start_secs_file, return_events=True)\n",
        "        pred_notes_ch, n_err_cnt_ch = merge_zipped_note_events_and_ties_to_notes(zipped_note_events_and_tie)\n",
        "        pred_notes_in_file.append(pred_notes_ch)\n",
        "        n_err_cnt += n_err_cnt_ch\n",
        "    pred_notes = mix_notes(pred_notes_in_file)  # This is the mixed notes from all channels\n",
        "\n",
        "    # Write MIDI\n",
        "    write_model_output_as_midi(pred_notes, '/content/',\n",
        "                              audio_info['track_name'], model.midi_output_inverse_vocab)\n",
        "    t.stop(); t.print_elapsed_time(\"post processing\");\n",
        "    midifile =  os.path.join('/content/model_output/', audio_info['track_name']  + '.mid')\n",
        "    assert os.path.exists(midifile)\n",
        "    return midifile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KOCH85AAYCTq"
      },
      "outputs": [],
      "source": [
        "# @title HTML helper\n",
        "import re\n",
        "import base64\n",
        "def to_data_url(midi_filename):\n",
        "    \"\"\" This is crucial for Colab/WandB support. Thanks to Scott Hawley!!\n",
        "        https://github.com/drscotthawley/midi-player/blob/main/midi_player/midi_player.py\n",
        "\n",
        "    \"\"\"\n",
        "    with open(midi_filename, \"rb\") as f:\n",
        "        encoded_string = base64.b64encode(f.read())\n",
        "    return 'data:audio/midi;base64,'+encoded_string.decode('utf-8')\n",
        "\n",
        "\n",
        "def to_youtube_embed_url(video_url):\n",
        "    regex = r\"(?:https:\\/\\/)?(?:www\\.)?(?:youtube\\.com|youtu\\.be)\\/(?:watch\\?v=)?(.+)\"\n",
        "    return re.sub(regex, r\"https://www.youtube.com/embed/\\1\",video_url)\n",
        "\n",
        "\n",
        "def create_html_from_midi(midifile):\n",
        "    html_template = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <title>Awesome MIDI Player</title>\n",
        "  <script src=\"https://cdn.jsdelivr.net/combine/npm/tone@14.7.58,npm/@magenta/music@1.23.1/es6/core.js,npm/focus-visible@5,npm/html-midi-player@1.5.0\">\n",
        "  </script>\n",
        "  <style>\n",
        "    /* Background color for the section */\n",
        "    #proll {{background-color:transparent}}\n",
        "\n",
        "    /* Custom player style */\n",
        "    #proll midi-player {{\n",
        "      display: block;\n",
        "      width: inherit;\n",
        "      margin: 4px;\n",
        "      margin-bottom: 0;\n",
        "    }}\n",
        "\n",
        "    #proll midi-player::part(control-panel) {{\n",
        "      background: #D8DAE8;\n",
        "      border-radius: 8px 8px 0 0;\n",
        "      border: 1px solid #A0A0A0;\n",
        "    }}\n",
        "\n",
        "    /* Custom visualizer style */\n",
        "    #proll midi-visualizer .piano-roll-visualizer {{\n",
        "      background: #F7FAFA;\n",
        "      border-radius: 0 0 8px 8px;\n",
        "      border: 1px solid #A0A0A0;\n",
        "      margin: 4px;\n",
        "      margin-top: 2;\n",
        "      overflow: auto;\n",
        "    }}\n",
        "\n",
        "    #proll midi-visualizer svg rect.note {{\n",
        "      opacity: 0.6;\n",
        "      stroke-width: 2;\n",
        "    }}\n",
        "\n",
        "    #proll midi-visualizer svg rect.note[data-instrument=\"0\"] {{\n",
        "      fill: #e22;\n",
        "      stroke: #055;\n",
        "    }}\n",
        "\n",
        "    #proll midi-visualizer svg rect.note[data-instrument=\"2\"] {{\n",
        "      fill: #2ee;\n",
        "      stroke: #055;\n",
        "    }}\n",
        "\n",
        "    #proll midi-visualizer svg rect.note[data-is-drum=\"true\"] {{\n",
        "      fill: #888;\n",
        "      stroke: #888;\n",
        "    }}\n",
        "\n",
        "    #proll midi-visualizer svg rect.note.active {{\n",
        "      opacity: 0.9;\n",
        "      stroke: #34384F;\n",
        "    }}\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <div>\n",
        "    <a href=\"{midifile}\" target=\"_blank\">Download MIDI</a> <br>\n",
        "    <section id=\"proll\">\n",
        "      <midi-player src=\"{midifile}\" sound-font=\"https://storage.googleapis.com/magentadata/js/soundfonts/sgm_plus\" visualizer=\"#proll midi-visualizer\">\n",
        "      </midi-player>\n",
        "      <midi-visualizer src=\"{midifile}\">\n",
        "      </midi-visualizer>\n",
        "    </section>\n",
        "  </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\".format(midifile=midifile)\n",
        "    html = f\"\"\"<iframe style=\"width: 100%; height: 400px; overflow:auto\" srcdoc='{html_template}'></iframe>\"\"\"\n",
        "    return html\n",
        "\n",
        "def create_html_youtube_player(youtube_url):\n",
        "    youtube_url = to_youtube_embed_url(youtube_url)\n",
        "    html = f\"\"\"<iframe width=\"560\" height=\"315\" src='{youtube_url}' title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\"\"\"\n",
        "    return html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O5bxMNAwzgEw"
      },
      "outputs": [],
      "source": [
        "# @title GradIO helper\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "from typing import Tuple, Dict, Literal\n",
        "from ctypes import ArgumentError\n",
        "from google.colab import output\n",
        "\n",
        "from pytube import YouTube\n",
        "import gradio as gr\n",
        "import torchaudio\n",
        "\n",
        "def prepare_media(source_path_or_url: os.PathLike,\n",
        "                  source_type: Literal['audio_filepath', 'youtube_url'],\n",
        "                  delete_video: bool = True) -> Dict:\n",
        "    \"\"\"prepare media from source path or youtube, and return audio info\"\"\"\n",
        "    # Get audio_file\n",
        "    if source_type == 'audio_filepath':\n",
        "        audio_file = source_path_or_url\n",
        "    elif source_type == 'youtube_url':\n",
        "        # Download from youtube\n",
        "        try:\n",
        "            # Try PyTube first\n",
        "            yt = YouTube(source_path_or_url)\n",
        "            audio_stream = min(yt.streams.filter(only_audio=True), key=lambda s: s.bitrate)\n",
        "            mp4_file = audio_stream.download(output_path='downloaded') # ./downloaded\n",
        "            audio_file = mp4_file[:-3] + 'mp3'\n",
        "            subprocess.run(['ffmpeg', '-i', mp4_file, '-ac', '1', audio_file])\n",
        "            os.remove(mp4_file)\n",
        "        except Exception as e:\n",
        "            try:\n",
        "                # Try alternative\n",
        "                print(f\"Failed with PyTube, error: {e}. Trying yt-dlp...\")\n",
        "                audio_file = './downloaded/yt_audio'\n",
        "                subprocess.run(['yt-dlp', '-x', source_path_or_url, '-f', 'bestaudio',\n",
        "                    '-o', audio_file, '--audio-format', 'mp3', '--restrict-filenames',\n",
        "                    '--force-overwrites'])\n",
        "                audio_file += '.mp3'\n",
        "            except Exception as e:\n",
        "                print(f\"Alternative downloader failed, error: {e}. Please try again later!\")\n",
        "                return None\n",
        "    else:\n",
        "        raise ValueError(source_type)\n",
        "\n",
        "    # Create info\n",
        "    info = torchaudio.info(audio_file)\n",
        "    return {\n",
        "        \"filepath\": audio_file,\n",
        "        \"track_name\": os.path.basename(audio_file).split('.')[0],\n",
        "        \"sample_rate\": int(info.sample_rate),\n",
        "        \"bits_per_sample\": int(info.bits_per_sample),\n",
        "        \"num_channels\": int(info.num_channels),\n",
        "        \"num_frames\": int(info.num_frames),\n",
        "        \"duration\": int(info.num_frames / info.sample_rate),\n",
        "        \"encoding\": str.lower(info.encoding),\n",
        "        }\n",
        "\n",
        "def process_audio(audio_filepath):\n",
        "    if audio_filepath is None:\n",
        "        return None\n",
        "    audio_info = prepare_media(audio_filepath, source_type='audio_filepath')\n",
        "    midifile = transcribe(model, audio_info)\n",
        "    midifile = to_data_url(midifile)\n",
        "    return create_html_from_midi(midifile) # html midiplayer\n",
        "\n",
        "def process_video(youtube_url):\n",
        "    if 'youtu' not in youtube_url:\n",
        "        return None\n",
        "    audio_info = prepare_media(youtube_url, source_type='youtube_url')\n",
        "    midifile = transcribe(model, audio_info)\n",
        "    midifile = to_data_url(midifile)\n",
        "    return create_html_from_midi(midifile) # html midiplayer\n",
        "\n",
        "def play_video(youtube_url):\n",
        "    if 'youtu' not in youtube_url:\n",
        "        return None\n",
        "    return create_html_youtube_player(youtube_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nS-Ka4htMngj"
      },
      "outputs": [],
      "source": [
        "# @title Load Checkpoint\n",
        "model_name = 'YPTF.MoE+Multi (PS)' # @param [\"YMT3+\", \"YPTF+Single (noPS)\", \"YPTF+Multi (PS)\", \"YPTF.MoE+Multi (noPS)\", \"YPTF.MoE+Multi (PS)\"]\n",
        "precision = '16' # @param [\"32\", \"bf16-mixed\", \"16\"]\n",
        "project = '2024'\n",
        "\n",
        "if model_name == \"YMT3+\":\n",
        "    checkpoint = \"notask_all_cross_v6_xk2_amp0811_gm_ext_plus_nops_b72@model.ckpt\"\n",
        "    args = [checkpoint, '-p', project, '-pr', precision]\n",
        "elif model_name == \"YPTF+Single (noPS)\":\n",
        "    checkpoint = \"ptf_all_cross_rebal5_mirst_xk2_edr005_attend_c_full_plus_b100@model.ckpt\"\n",
        "    args = [checkpoint, '-p', project, '-enc', 'perceiver-tf', '-ac', 'spec',\n",
        "            '-hop', '300', '-atc', '1', '-pr', precision]\n",
        "elif model_name == \"YPTF+Multi (PS)\":\n",
        "    checkpoint = \"mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b80_ps2@model.ckpt\"\n",
        "    args = [checkpoint, '-p', project, '-tk', 'mc13_full_plus_256',\n",
        "            '-dec', 'multi-t5', '-nl', '26', '-enc', 'perceiver-tf',\n",
        "            '-ac', 'spec', '-hop', '300', '-atc', '1', '-pr', precision]\n",
        "elif model_name == \"YPTF.MoE+Multi (noPS)\":\n",
        "    checkpoint = \"mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops@last.ckpt\"\n",
        "    args = [checkpoint, '-p', project, '-tk', 'mc13_full_plus_256', '-dec', 'multi-t5',\n",
        "            '-nl', '26', '-enc', 'perceiver-tf', '-sqr', '1', '-ff', 'moe',\n",
        "            '-wf', '4', '-nmoe', '8', '-kmoe', '2', '-act', 'silu', '-epe', 'rope',\n",
        "            '-rp', '1', '-ac', 'spec', '-hop', '300', '-atc', '1', '-pr', precision]\n",
        "elif model_name == \"YPTF.MoE+Multi (PS)\":\n",
        "    checkpoint = \"mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b80_ps2@model.ckpt\"\n",
        "    args = [checkpoint, '-p', project, '-tk', 'mc13_full_plus_256', '-dec', 'multi-t5',\n",
        "            '-nl', '26', '-enc', 'perceiver-tf', '-sqr', '1', '-ff', 'moe',\n",
        "            '-wf', '4', '-nmoe', '8', '-kmoe', '2', '-act', 'silu', '-epe', 'rope',\n",
        "            '-rp', '1', '-ac', 'spec', '-hop', '300', '-atc', '1', '-pr', precision]\n",
        "else:\n",
        "    raise ValueError(model_name)\n",
        "\n",
        "model = load_model_checkpoint(args=args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWFvv2vObQAz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Run GradIO\n",
        "output.no_vertical_scroll()\n",
        "\n",
        "AUDIO_EXAMPLES = glob.glob('/content/examples/*.*', recursive=True)\n",
        "YOUTUBE_EXAMPLES = [\"https://www.youtube.com/watch?v=vMboypSkj3c\"]\n",
        "\n",
        "theme = 'gradio/dracula_revamped' #'Insuz/Mocha' #gr.themes.Soft()\n",
        "with gr.Blocks(theme=theme) as demo:\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=10):\n",
        "            gr.Markdown(\n",
        "            \"\"\"\n",
        "            # YourMT3+: Bridging the Gap in Multi-instrument Music Transcription with Advanced Model Architectures and Cross-dataset Stem Augmentation\n",
        "            \"\"\")\n",
        "\n",
        "    with gr.Group():\n",
        "        with gr.Tab(\"Upload audio\"):\n",
        "            # Input\n",
        "            audio_input = gr.Audio(label=\"Record Audio\", type=\"filepath\",\n",
        "                                show_share_button=True, show_download_button=True)\n",
        "            # Display examples\n",
        "            gr.Examples(examples=AUDIO_EXAMPLES, inputs=audio_input)\n",
        "            # Submit button\n",
        "            transcribe_audio_button = gr.Button(\"Transcribe\", variant=\"primary\")\n",
        "            # Transcribe\n",
        "            output_tab1 = gr.HTML()\n",
        "            # audio_output = gr.Text(label=\"Audio Info\")\n",
        "            # transcribe_audio_button.click(process_audio, inputs=audio_input, outputs=output_tab1)\n",
        "            transcribe_audio_button.click(process_audio, inputs=audio_input, outputs=output_tab1)\n",
        "\n",
        "        with gr.Tab(\"From YouTube\"):\n",
        "            with gr.Row():\n",
        "                # Input URL\n",
        "                youtube_url = gr.Textbox(label=\"YouTube Link URL\",\n",
        "                        placeholder=\"https://youtu.be/...\")\n",
        "                # Play youtube\n",
        "                youtube_player = gr.HTML(render=True)\n",
        "            with gr.Row():\n",
        "                # Play button\n",
        "                play_video_button = gr.Button(\"Play\", variant=\"primary\")\n",
        "                # Submit button\n",
        "                transcribe_video_button = gr.Button(\"Transcribe\", variant=\"primary\")\n",
        "            # Transcribe\n",
        "            output_tab2 = gr.HTML(render=True)\n",
        "            # video_output = gr.Text(label=\"Video Info\")\n",
        "            transcribe_video_button.click(process_video, inputs=youtube_url, outputs=output_tab2)\n",
        "            # Play\n",
        "            play_video_button.click(play_video, inputs=youtube_url, outputs=youtube_player)\n",
        "\n",
        "            # Display examples\n",
        "            gr.Examples(examples=YOUTUBE_EXAMPLES, inputs=youtube_url)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}